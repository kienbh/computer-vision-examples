{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 01 ¬∑ Digital Imaging Fundamentals\n",
    "\n",
    "**Course:** Computer Vision (BCSE)  \n",
    "**Instructor:** B√πi Huy Ki√™n  \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Learning Objectives\n",
    "By the end of this lab, students should be able to:\n",
    "- Understand the concept of a digital image (pixel, matrix representation).\n",
    "- Explain sampling, quantization, and resolution.\n",
    "- Manipulate and display images using OpenCV.\n",
    "- Observe the effect of reducing resolution and gray levels.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìò Theory Recap\n",
    "- **Digital Image** = 2D matrix of pixels.\n",
    "- **Sampling** = choosing how many pixels to represent the image.\n",
    "- **Quantization** = deciding how many intensity levels (gray levels) each pixel can take.\n",
    "- **Resolution** = determined by both sampling and quantization.\n",
    "- **Color Representation** = RGB, Grayscale, HSV.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# For inline plots\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Load image\n",
    "img = cv2.imread(\"lena.png\")   # replace with any image file\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.imshow(img_rgb)\n",
    "plt.title(\"Original Image\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Show shape and a few pixel values\n",
    "print(\"Image shape (H, W, C):\", img_rgb.shape)\n",
    "print(\"Pixel at (50,50):\", img_rgb[50,50])  # R,G,B values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def downsample(img, factor):\n",
    "    h, w = img.shape[:2]\n",
    "    return cv2.resize(img, (w//factor, h//factor), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "fig, axes = plt.subplots(1,3, figsize=(12,4))\n",
    "axes[0].imshow(img_rgb)\n",
    "axes[0].set_title(\"Original\")\n",
    "axes[0].axis(\"off\")\n",
    "\n",
    "axes[1].imshow(downsample(img_rgb, 4))\n",
    "axes[1].set_title(\"1/4 Resolution\")\n",
    "axes[1].axis(\"off\")\n",
    "\n",
    "axes[2].imshow(downsample(img_rgb, 8))\n",
    "axes[2].set_title(\"1/8 Resolution\")\n",
    "axes[2].axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def quantize_gray(img, levels):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    max_val = 256\n",
    "    step = max_val // levels\n",
    "    return (gray // step) * step\n",
    "\n",
    "levels = [256, 16, 8, 4]\n",
    "fig, axes = plt.subplots(1, len(levels), figsize=(16,4))\n",
    "for i, l in enumerate(levels):\n",
    "    q = quantize_gray(img_rgb, l)\n",
    "    axes[i].imshow(q, cmap=\"gray\")\n",
    "    axes[i].set_title(f\"Quantization: {l} levels\")\n",
    "    axes[i].axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "r, g, b = cv2.split(img_rgb)\n",
    "\n",
    "fig, axes = plt.subplots(1,4, figsize=(16,4))\n",
    "axes[0].imshow(img_rgb)\n",
    "axes[0].set_title(\"Original\")\n",
    "axes[0].axis(\"off\")\n",
    "\n",
    "axes[1].imshow(r, cmap=\"Reds\")\n",
    "axes[1].set_title(\"Red Channel\")\n",
    "axes[1].axis(\"off\")\n",
    "\n",
    "axes[2].imshow(g, cmap=\"Greens\")\n",
    "axes[2].set_title(\"Green Channel\")\n",
    "axes[2].axis(\"off\")\n",
    "\n",
    "axes[3].imshow(b, cmap=\"Blues\")\n",
    "axes[3].set_title(\"Blue Channel\")\n",
    "axes[3].axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "## üìù Exercises\n",
    "1. Load another image (your own photo or dataset sample) and repeat the experiments.\n",
    "2. Try different sampling factors (e.g., 2, 4, 10) and observe the difference.\n",
    "3. Quantize the image to 2 gray levels (black/white). Compare with simple thresholding.\n",
    "4. Explain how sampling and quantization affect image quality.\n",
    "5. (Optional) Convert the image to HSV and display Hue, Saturation, and Value channels.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
